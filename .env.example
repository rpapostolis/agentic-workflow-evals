# =============================================================================
# AgentEval — Local Configuration
# Copy to .env and adjust as needed. No cloud services required by default.
# =============================================================================

# -- Ollama -------------------------------------------------------------------
# Shared Ollama connection used by all components (only needed for Ollama mode)
OLLAMA_HOST=http://localhost:11434

# -- Judge LLM ----------------------------------------------------------------
# Text model used by the eval judge and comparison explainer.
#
# Option A — Ollama (local, default, no API key):
LLM_BASE_URL=${OLLAMA_HOST}/v1
LLM_API_KEY=ollama
LLM_MODEL=qwen3-coder:latest
#
# Option B — Anthropic Claude (cloud):
# LLM_BASE_URL=https://api.anthropic.com/v1
# LLM_API_KEY=sk-ant-...           # or set ANTHROPIC_API_KEY env var
# LLM_MODEL=claude-haiku-4-5

# -- Computer Use Agent (CUA) -------------------------------------------------
# CUA_MODE selects the browser automation backend:
#   "ollama"  — local Ollama vision model (default, no API key needed)
#   "claude"  — Anthropic Claude API (requires ANTHROPIC_API_KEY or LLM_API_KEY)
CUA_MODE=ollama

# Claude CUA model (only used when CUA_MODE=claude)
# Balanced (recommended):
CUA_MODEL=claude-sonnet-4-5-20250929
# Higher quality (uses computer_20251124 tool with zoom):
#CUA_MODEL=claude-opus-4-6
# Fastest / cheapest:
#CUA_MODEL=claude-haiku-4-5-20251001
# CUA_API_KEY=sk-ant-...           # optional — falls back to LLM_API_KEY then ANTHROPIC_API_KEY

# Ollama vision model (only used when CUA_MODE=ollama)
# Recommended: qwen3-vl:latest (small/fast), qwen2.5vl:7b (balanced), qwen2.5vl:72b (best)
# Or build a custom model: ollama create cua-agent -f src/agents/computer_use/Modelfile
OLLAMA_MODEL=qwen3-vl:latest
CU_NUM_CTX=8192               # context window tokens (higher = more RAM)

# Shared CUA settings
CU_HEADLESS=false
# CU_ACTION_TIMEOUT=30        # seconds per step (default: 30 ollama, 60 claude)
# CU_VIEWPORT_WIDTH=1280      # browser viewport width
# CU_VIEWPORT_HEIGHT=720      # browser viewport height
# CU_AGENT_MAX_STEPS=15       # max browser actions per task

# -- API Server ---------------------------------------------------------------
API_TITLE=AgentEval
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false
CORS_ORIGINS=http://localhost:3000,http://localhost:5000,http://localhost:5001,http://localhost:5173

# -- Web App ------------------------------------------------------------------
VITE_API_URL=http://localhost:${API_PORT}/api
# VITE_PORT=5001              # Vite dev server port

# -- MCP Agent ----------------------------------------------------------------
MCP_SERVER_URL=http://localhost:${API_PORT}/mcp

# -- Evaluation & Performance -------------------------------------------------
# EVALUATION_TIMEOUT_SECONDS=900  # 15 min -- CU Agent with larger models needs time
# MAX_CONCURRENT_TESTS=1          # parallel test cases (lower if resource-constrained)
# SQLITE_DB_PATH=./data/evals.db

# -- Retry & Resilience -------------------------------------------------------
# RETRY_MAX_ATTEMPTS=5
# RETRY_BASE_DELAY=2.0
# RETRY_MAX_DELAY=60.0

# -- Production Tracing -------------------------------------------------------
# PRODUCTION_TRACE_RETENTION_DAYS=90
# TRACE_BATCH_SIZE=1000
# ENABLE_PII_DETECTION=true       # auto-scan traces for PII (email, SSN, etc.)

# -- Telemetry & Sampling -----------------------------------------------------
# DEFAULT_SAMPLING_RATE=0.15
# TIER_1_SAMPLING_RATE=1.0
